using System;
using System.Collections.Generic;
using Edu.Stanford.Nlp.Math;
using Edu.Stanford.Nlp.Util.Logging;
using Java.Util;
using Sharpen;

namespace Edu.Stanford.Nlp.Optimization
{
	/// <author>Alex Kleeman</author>
	public abstract class AbstractStochasticCachingDiffFunction : AbstractCachingDiffFunction
	{
		/// <summary>A logger for this class</summary>
		private static readonly Redwood.RedwoodChannels log = Redwood.Channels(typeof(AbstractStochasticCachingDiffFunction));

		public bool hasNewVals = true;

		public bool recalculatePrevBatch = false;

		public bool returnPreviousValues = false;

		protected internal int lastBatchSize = 0;

		protected internal int[] lastBatch = null;

		protected internal int[] thisBatch = null;

		protected internal double[] lastXBatch = null;

		protected internal double[] lastVBatch = null;

		protected internal int lastElement = 0;

		protected internal double[] HdotV = null;

		protected internal double[] gradPerturbed = null;

		protected internal double[] xPerturbed = null;

		protected internal int curElement = 0;

		protected internal IList<int> allIndices = null;

		protected internal Random randGenerator = new Random(1);

		protected internal bool scaleUp = false;

		private int[] shuffledArray = null;

		public enum SamplingMethod
		{
			NoneSpecified,
			RandomWithReplacement,
			RandomWithoutReplacement,
			Ordered,
			Shuffled
		}

		// protected double[] extFiniteDiffDerivative = null;
		//System.currentTimeMillis());
		public virtual void IncrementRandom(int numTimes)
		{
			log.Info("incrementing random " + numTimes + " times.");
			for (int i = 0; i < numTimes; i++)
			{
				randGenerator.NextInt(this.DataDimension());
			}
		}

		public virtual void ScaleUp(bool toScaleUp)
		{
			scaleUp = toScaleUp;
		}

		public StochasticCalculateMethods method = StochasticCalculateMethods.ExternalFiniteDifference;

		public AbstractStochasticCachingDiffFunction.SamplingMethod sampleMethod = AbstractStochasticCachingDiffFunction.SamplingMethod.RandomWithoutReplacement;

		/// <summary>finiteDifferenceStepSize - this is the fixed step size for the finite difference approximation.</summary>
		/// <remarks>
		/// finiteDifferenceStepSize - this is the fixed step size for the finite difference approximation.
		/// a few tests were run using the SMD minimizer, and step sizes of 1e-4 to 1e-3 seemed to be ideal.
		/// (akleeman)
		/// </remarks>
		protected internal double finiteDifferenceStepSize = 1e-4;

		/// <summary>
		/// calculateStochastic needs to calculate a stochastic approximation to the derivative and value of
		/// of a function for a given batch of the data.
		/// </summary>
		/// <remarks>
		/// calculateStochastic needs to calculate a stochastic approximation to the derivative and value of
		/// of a function for a given batch of the data.  The approximation to the derivative must be stored
		/// in the array
		/// <c>derivative</c>
		/// , the approximation to the value in
		/// <c>value</c>
		/// and the approximation to the Hessian vector product H.v in the array
		/// <c>HdotV</c>
		/// .  Note
		/// that the hessian vector product is used primarily with the Stochastic Meta Descent optimization
		/// routine
		/// <c>SMDMinimizer</c>
		/// .
		/// <p>
		/// Important: The stochastic approximation must be such that the sum of all stochastic calculations over
		/// each of the batches in the data must equal the full calculation.  i.e. for a data set of size 100
		/// the sum of the gradients for batches 1-10 , 11-20 , 21-30 .... 91-100 must be the same as the gradient
		/// for the full calculation (at the very least in expectation).  Be sure to take into account the priors.
		/// </remarks>
		/// <param name="x">Value to evaluate at</param>
		/// <param name="v">The vector for the Hessian vector product H.v</param>
		/// <param name="batch">
		/// An array containing the indices of the data to use in the calculation, this array is being calculated
		/// internal to the abstract, and only needs to be handled not generated by the implementation.
		/// </param>
		public abstract void CalculateStochastic(double[] x, double[] v, int[] batch);

		/// <summary>Data dimension must return the size of the data used by the function.</summary>
		public abstract int DataDimension();

		/// <summary>Clears the cache in a way that doesn't require reallocation :-).</summary>
		protected internal override void ClearCache()
		{
			base.ClearCache();
			if (lastXBatch != null)
			{
				lastXBatch[0] = double.NaN;
			}
			if (lastVBatch != null)
			{
				lastVBatch[0] = double.NaN;
			}
		}

		public override double[] Initial()
		{
			double[] initial = new double[DomainDimension()];
			// Arrays.fill(initial, 0.0); // not needed; Java arrays zero initialized
			return initial;
		}

		/// <summary>decrementBatch - This decrements the curElement variable by the amount batchSize.</summary>
		/// <remarks>
		/// decrementBatch - This decrements the curElement variable by the amount batchSize.
		/// by decrementing the batch and then calling calculate you can recalculate over the previous batch.
		/// </remarks>
		public virtual void DecrementBatch(int batchSize)
		{
			curElement -= batchSize;
			if (curElement < 0)
			{
				curElement = 0;
			}
		}

		/// <summary>incrementBatch will shift the curElement variable to mark the next batch.</summary>
		/// <remarks>
		/// incrementBatch will shift the curElement variable to mark the next batch.  It also resets the flags:
		/// hasNewElements
		/// recalculatePrevBatch
		/// returnPreviousValues
		/// </remarks>
		public virtual void IncrementBatch(int batchSize)
		{
			curElement += batchSize;
			hasNewVals = false;
			recalculatePrevBatch = false;
			returnPreviousValues = false;
		}

		/// <summary>getBatch is used to generate the next sequence of indices to be passed to the actual function.</summary>
		/// <remarks>
		/// getBatch is used to generate the next sequence of indices to be passed to the actual function.
		/// Depending on the current sample method this is done by:
		/// Ordered - simply generates the indices 1,2,3,4,....
		/// RandomWithReplacement - Samples uniformly from the set of possible indices
		/// RandomWithoutReplacement - Samples from the set of possible indices removing each used index, then restarting
		/// after each pass
		/// </remarks>
		protected internal virtual void GetBatch(int batchSize)
		{
			//private int numCalls = 0;
			//      if (numCalls == 0) {
			//        for (int i = 0; i < 1538*\15; i++) {
			//          randGenerator.nextInt(this.dataDimension());
			//        }
			//      }
			//      numCalls++;
			if (thisBatch == null || thisBatch.Length != batchSize)
			{
				thisBatch = new int[batchSize];
			}
			//-----------------------------
			//Shuffled
			//-----------------------------
			if (sampleMethod == AbstractStochasticCachingDiffFunction.SamplingMethod.Shuffled)
			{
				if (shuffledArray == null)
				{
					shuffledArray = ArrayMath.Range(0, this.DataDimension());
				}
				for (int i = 0; i < batchSize; i++)
				{
					thisBatch[i] = shuffledArray[(curElement + i) % this.DataDimension()];
				}
				//Take the next batchSize points in order
				curElement = (curElement + batchSize) % this.DataDimension();
			}
			else
			{
				//watch out for overflow
				//-----------------------------
				//RANDOM WITH REPLACEMENT
				//-----------------------------
				if (sampleMethod == AbstractStochasticCachingDiffFunction.SamplingMethod.RandomWithReplacement)
				{
					for (int i = 0; i < batchSize; i++)
					{
						thisBatch[i] = randGenerator.NextInt(this.DataDimension());
					}
				}
				else
				{
					//Just generate a random index
					//        log.info("numCalls = "+(numCalls++));
					//-----------------------------
					//ORDERED
					//-----------------------------
					if (sampleMethod == AbstractStochasticCachingDiffFunction.SamplingMethod.Ordered)
					{
						for (int i = 0; i < batchSize; i++)
						{
							thisBatch[i] = (curElement + i) % this.DataDimension();
						}
						//Take the next batchSize points in order
						curElement = (curElement + batchSize) % this.DataDimension();
					}
					else
					{
						//watch out for overflow
						//-----------------------------
						//RANDOM WITHOUT REPLACEMENT
						//-----------------------------
						if (sampleMethod == AbstractStochasticCachingDiffFunction.SamplingMethod.RandomWithoutReplacement)
						{
							//Declare the indices array if needed.
							if (allIndices == null || allIndices.Count != this.DataDimension())
							{
								allIndices = new List<int>();
								for (int i = 0; i < this.DataDimension(); i++)
								{
									allIndices.Add(i);
								}
								Java.Util.Collections.Shuffle(allIndices, randGenerator);
							}
							for (int i_1 = 0; i_1 < batchSize; i_1++)
							{
								thisBatch[i_1] = allIndices[(curElement + i_1) % allIndices.Count];
							}
							//Grab the next batchSize indices
							if (curElement + batchSize > this.DataDimension())
							{
								Java.Util.Collections.Shuffle(allIndices, randGenerator);
							}
							//Shuffle if we got to the end of the list
							//watch out for overflow
							curElement = (curElement + batchSize) % allIndices.Count;
						}
						else
						{
							//Rollover
							throw new InvalidOperationException("NO SAMPLING METHOD SELECTED");
						}
					}
				}
			}
		}

		private void StochasticEnsure(double[] x, double[] v, int batchSize)
		{
			if (lastXBatch == null)
			{
				lastXBatch = new double[DomainDimension()];
				log.Info("Setting previous position (x).");
			}
			if (lastVBatch == null)
			{
				lastVBatch = new double[DomainDimension()];
				log.Info("Setting previous gain (v)");
			}
			if (derivative == null)
			{
				derivative = new double[DomainDimension()];
				log.Info("Setting Derivative.");
			}
			if (HdotV == null)
			{
				HdotV = new double[DomainDimension()];
				log.Info("Setting HdotV.");
			}
			if (lastBatch == null)
			{
				lastBatch = new int[batchSize];
				log.Info("Setting last batch");
			}
			//If we want to recalculate using the previous batch
			if (recalculatePrevBatch && batchSize == lastBatch.Length)
			{
				thisBatch = lastBatch;
			}
			else
			{
				/*
				If we dont want to calculate anything we just want the last values.  This is especially useful if you know
				the values have already been calculated, and you don't want to waste time comparing the entire
				array of x's and v's.
				*/
				if (returnPreviousValues)
				{
					returnPreviousValues = false;
					return;
				}
				//If we dont know there are new values, and we havnt asked to recalculate then compare
				//to avoid needing to recalculate
				if (!hasNewVals && lastElement != curElement)
				{
					if ((lastBatchSize == batchSize) && Arrays.Equals(x, lastXBatch) && Arrays.Equals(v, lastVBatch) && Arrays.Equals(thisBatch, lastBatch))
					{
						return;
					}
				}
				GetBatch(batchSize);
			}
			Copy(lastXBatch, x);
			if (lastBatch.Length != batchSize)
			{
				lastBatch = new int[batchSize];
			}
			System.Array.Copy(thisBatch, 0, lastBatch, 0, thisBatch.Length);
			if (v != null)
			{
				Copy(lastVBatch, v);
			}
			lastBatchSize = batchSize;
			CalculateStochastic(x, v, thisBatch);
			//This is used to make the function evaluation equal the true function in expectation.
			if (scaleUp)
			{
				double ratio = ((double)this.DataDimension()) / ((double)batchSize);
				for (int i = 0; i < x.Length; i++)
				{
					derivative[i] = derivative[i] * ratio;
				}
				value = ratio * value;
			}
			IncrementBatch(batchSize);
			lastElement = curElement;
		}

		/*
		void stochasticEnsure(double[] x, double[] v, int batchSize) {
		
		
		if (lastXBatch == null) {
		lastXBatch = new double[domainDimension()];
		System.out.println("Setting previous position (x).");
		}
		
		if (lastVBatch == null) {
		lastVBatch = new double[domainDimension()];
		System.out.println("Setting previous gain (v)");
		}
		
		if (derivative == null) {
		derivative = new double[domainDimension()];
		System.out.println("Setting Derivative.");
		}
		
		if (HdotV == null) {
		HdotV = new double[domainDimension()];
		System.out.println("Setting HdotV.");
		}
		
		
		
		//If we want to recalculate using the previous batch
		if(recalculatePrevBatch){
		
		decrementBatch(batchSize);
		
		}else{
		
		//
		//If we dont want to calculate anything we just want the last values.  This is especially usefull if you know
		//   the values have already been calculated, and you don't want to waste time comparing the entire
		//   array of x's and v's.
		//
		if(returnPreviousValues){
		returnPreviousValues = false;
		return;
		}
		
		//If we dont know there are new values, and we havnt asked to recalculate then compare
		//to avoid needing to recalculate
		if( !hasNewVals && lastElement!=curElement ){
		if ((lastBatchSize==batchSize) && Arrays.equals(x, lastXBatch) && Arrays.equals(v,lastVBatch)) {
		return;
		}
		}
		
		}
		
		
		copy(lastXBatch,x);
		if(v!=null){copy(lastVBatch,v);}
		lastBatchSize = batchSize;
		calculateStochastic(x,v,batchSize);
		
		lastElement = curElement;
		
		incrementBatch(batchSize);
		
		}
		*/
		/// <summary>
		/// valueAt(x,batchSize)   derivativeAt(x,batchSize)
		/// invokes the calculateStochastic function to get the current value at x for the next batchSize data points.
		/// </summary>
		/// <remarks>
		/// valueAt(x,batchSize)   derivativeAt(x,batchSize)
		/// invokes the calculateStochastic function to get the current value at x for the next batchSize data points.  Will
		/// not return a HdotV since it passes v = null;
		/// </remarks>
		public virtual double ValueAt(double[] x, int batchSize)
		{
			StochasticEnsure(x, null, batchSize);
			return value;
		}

		public virtual double[] DerivativeAt(double[] x, int batchSize)
		{
			StochasticEnsure(x, null, batchSize);
			return derivative;
		}

		/// <summary>This function will return the stochastic approximation at the point x.</summary>
		/// <remarks>
		/// This function will return the stochastic approximation at the point x.  the vector v is the vector
		/// to be used in the vector product H.v.
		/// passing v = null will simply revert to a calculation without the hessian vector product.
		/// </remarks>
		public virtual double ValueAt(double[] x, double[] v, int batchSize)
		{
			StochasticEnsure(x, v, batchSize);
			return value;
		}

		public virtual double[] DerivativeAt(double[] x, double[] v, int batchSize)
		{
			StochasticEnsure(x, v, batchSize);
			return derivative;
		}

		/// <summary>Calculate the Hessian vector product with a vector v of the current function based on a finite difference approximation.</summary>
		/// <remarks>
		/// Calculate the Hessian vector product with a vector v of the current function based on a finite difference approximation.
		/// This is done using the approximation:
		/// H.v ~ ( Grad( x + h * v ) - Grad( x ) ) / h
		/// Note that this method will not be exact, and the value of h should be choosen to be small enough to avoid truncation error
		/// due to neglecting second order taylor series terms, and big enough to avoid numerical error which is almost gaurenteed
		/// since the operation involves subtracting similar values and dividing by a small number.  In general a step size of
		/// h = 1e-4 has proved to provide accurate enough calculations.
		/// </remarks>
		/// <param name="x">the point at which the hessian should be calculated</param>
		/// <param name="v">the vector for the vector product ... thus the function will return  H(x) . v</param>
		/// <param name="curDerivative">the derivative at x.  Note this must have been calculated using the same batchSize</param>
		private void GetHdotVFiniteDifference(double[] x, double[] v, double[] curDerivative)
		{
			double h = finiteDifferenceStepSize;
			double hInv = 1 / h;
			// this avoids dividing too much since it's a bit more expensive than multiplying
			if (gradPerturbed == null)
			{
				gradPerturbed = new double[x.Length];
				System.Console.Out.WriteLine("Setting approximate gradient.");
			}
			if (xPerturbed == null)
			{
				xPerturbed = new double[x.Length];
				System.Console.Out.WriteLine("Setting perturbed.");
			}
			if (HdotV == null)
			{
				HdotV = new double[x.Length];
				System.Console.Out.WriteLine("Setting H dot V.");
			}
			//  This adds h*v to x  --->  x = x + h*v
			for (int i = 0; i < x.Length; i++)
			{
				xPerturbed[i] = x[i] + h * v[i];
			}
			double prevValue = value;
			recalculatePrevBatch = true;
			CalculateStochastic(xPerturbed, null, thisBatch);
			// Call the calculate function without updating the batch
			// System.arraycopy(derivative, 0, gradPerturbed, 0, gradPerturbed.length);
			//  This comes up with the approximate difference, and renormalizes it on h.
			for (int i_1 = 0; i_1 < x.Length; i_1++)
			{
				double tmp = (derivative[i_1] - curDerivative[i_1]);
				HdotV[i_1] = hInv * (tmp);
			}
			//Make sure the original derivative is in place
			System.Array.Copy(curDerivative, 0, derivative, 0, derivative.Length);
			value = prevValue;
			hasNewVals = false;
			recalculatePrevBatch = false;
			returnPreviousValues = false;
		}

		/// <summary>
		/// HdotVAt  will return the hessian vector product H.v at the point x for a batchSize subset of the data
		/// There are several ways to perform this calculation, as of now Finite Difference, and Algorithmic Differentiation
		/// are the methods that have been used.
		/// </summary>
		/// <remarks>
		/// HdotVAt  will return the hessian vector product H.v at the point x for a batchSize subset of the data
		/// There are several ways to perform this calculation, as of now Finite Difference, and Algorithmic Differentiation
		/// are the methods that have been used.  To use this function calculateStochastic must also fill the array
		/// Hv with the hessian vector product.
		/// Alternative:  use the function getHdotVFiniteDifference which will simply make two calls to the function and
		/// come up with an approximation to this value.
		/// </remarks>
		public virtual double[] HdotVAt(double[] x, double[] v, int batchSize)
		{
			if (method == StochasticCalculateMethods.ExternalFiniteDifference)
			{
				throw new Exception("Attempt to use ExternalFiniteDifference without passing currentDerivative");
			}
			else
			{
				/*
				if( extFiniteDiffDerivative == null )
				extFiniteDiffDerivative = new double[x.length];
				
				System.arraycopy(derivativeAt(x,x,batchSize),0,extFiniteDiffDerivative,0,extFiniteDiffDerivative.length);
				getHdotVFiniteDifference(x,v,extFiniteDiffDerivative,batchSize);
				*/
				//Call the objective Function
				StochasticEnsure(x, v, batchSize);
			}
			return HdotV;
		}

		public virtual double[] HdotVAt(double[] x, double[] v, double[] curDerivative, int batchSize)
		{
			if (method == StochasticCalculateMethods.ExternalFiniteDifference)
			{
				//If H.v is going to be calculated by using Finite Difference using two calls to the objective Function
				//
				//note:  This assumes that the derivative was calculated at x already.
				GetHdotVFiniteDifference(x, v, curDerivative);
			}
			else
			{
				//Call the objective Function
				StochasticEnsure(x, v, batchSize);
			}
			return HdotV;
		}

		public virtual double[] HdotVAt(double[] x, double[] v)
		{
			if (method == StochasticCalculateMethods.ExternalFiniteDifference)
			{
				log.Info("Attempt to use ExternalFiniteDifference without passing currentDerivative");
				throw new Exception();
			}
			//Call the objective Function
			StochasticEnsure(x, v, this.DataDimension());
			//Roll back the batch to the previous val.
			DecrementBatch(this.DataDimension());
			return HdotV;
		}

		public virtual double[] LastDerivative()
		{
			return derivative;
		}

		public override double LastValue()
		{
			return value;
		}
		// It doesn't seem like this should exist in the class and it wasn't used.
		// public void setValue(double v) {
		//   value = v;
		// }
	}
}
